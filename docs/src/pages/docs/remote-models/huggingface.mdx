---
title: Hugging Face
description: Learn how to integrate Hugging Face Inference Endpoints with Jan for enhanced functionality.
keywords:
  [
    Hugging Face,
    Jan,
    Jan AI,
    Hugging Face Inference Endpoints,
    Hugging Face API,
    Hugging Face Integration,
    Hugging Face API Integration
  ]
---

import { Callout, Steps } from 'nextra/components'
import { Settings, Plus } from 'lucide-react'

# Hugging Face

Jan supports lots of models hosted on [Hugging Face](https://huggingface.co/). The main thing to keep 
in mind is that **the method you use to deploy the model via huggingface has to be compatible with the 
OpenAI API**.

## Integrate Hugging Face API with Jan

<Steps>

### Step 1: Navigate to the HuggingFace Model Hub

Visit the [HuggingFace Model Hub](https://huggingface.co/models) (make sure you are logged in) and 
pick the model you want to use

![HuggingFace Model Hub](../_assets/hf_hub.png)

### Step 2: Configure HF Inference Endpoint and Deploy

After you have selected the model you want to use, click on the **Deploy** button and select a 
deployment method. We will select HF Inference Endpoints for this one.

![HuggingFace Deployment](../_assets/hf_jan_nano.png)
<br/>

This will take you to the deployment set up page. For this example, we will leave the default settings 
as they are under the GPU tab and cick on **Create Endpoint**.

![HuggingFace Deployment](../_assets/hf_jan_nano_2.png)
<br/>

Once your endpoint is ready, test that it works on the **Test your endpoint** tab.

![HuggingFace Deployment](../_assets/hf_jan_nano_3.png)
<br/>

If you get a response, you can click on **Copy** to copy the endpoint URL and API key.

<Callout type='info'>
  You will need to be logged into the HuggingFace Inference Endpoints and have a credit card on file to deploy a model.
</Callout>

### Step 3: Configure Jan

If you do not have an API key you can create one under **Settings** > **Access Tokens** [here](https://huggingface.co/settings/tokens). Once 
you finish, copy the token and add it to Jan alongside you endpoint URL at **Settings** > **Model Providers** > **HuggingFace**.

**3.1 HF Token**
![Get Token](../_assets/hf_jan_nano_5.png)
<br/>

**3.2 HF Endpoint URL**
![Endpoint URL](../_assets/hf_jan_nano_4.png)
<br/>

**3.3 Jan Settings**
![Jan Settings](../_assets/hf_jan_nano_6.png)

<Callout type='warning'>
Make sure to add `/v1/` to the end of your endpoint URL. This is required by the OpenAI API.
</Callout>

**3.4 Add Model Details**
![Add Model Details](../_assets/hf_jan_nano_7.png)

### Step 4: Configure Jan

Now you can start using the model in any chat.

![Start Using the Model](../_assets/hf_jan_nano_8.png)

If you want to learn how to use Jan Nano with MCP, check out [the guide here](../jan-models/jan-nano-32).
<br/>

</Steps>

## Available Hugging Face Models

You can follow the steps above with a large amount of models on Hugging Face and bring them to Jan. Check 
out other models in the [Hugging Face Model Hub](https://huggingface.co/models).


## Troubleshooting

Common issues and solutions:

**1. Started a chat but the model is not responding**
- Verify your API_KEY/HF_TOKEN is correct and not expired
- Ensure the model you're trying to use is running again since, after a while, they go 
idle so that you don't get charged when you are not using it

![Model Running](../_assets/hf_jan_nano_9.png)

**2. Connection Problems**
- Check your internet connection
- Verify Hugging Face's system status
- Look for error messages in [Jan's logs](/docs/troubleshooting#how-to-get-error-logs)

**3. Model Unavailable**
- Confirm your API key has access to the model
- Check if you're using the correct model ID
- Verify your Hugging Face account has the necessary permissions

Need more help? Join our [Discord community](https://discord.gg/FTk2MvZwJH) or check the
[Hugging Face's documentation](https://docs.huggingface.co/en/inference-endpoints/index).
